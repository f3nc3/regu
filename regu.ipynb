{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sZ8HN9QAA4Qv"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from mlxtend.plotting import plot_decision_regions\n",
        "from matplotlib.colors import ListedColormap\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_circles, make_moons"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(800)\n",
        "# Create a dataset of moons with some noise\n",
        "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
        "zero_one_colormap = ListedColormap(['red', 'green'])\n",
        "rcParams['figure.figsize'] = 8, 5\n",
        "# Assign the scatter plot to the variable 'scatter'\n",
        "scatter = plt.scatter(X[:, 0], X[:,1],c=y, s=100,cmap=zero_one_colormap)\n",
        "# Call 'scatter.legend_elements()' using the correctly defined variable 'scatter'\n",
        "legend1 = plt.legend(*scatter.legend_elements(),\n",
        "                    loc=\"upper right\", title=\"Classes\")\n",
        "plt.title('Dataset of Moons')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ukjRuH94BCNP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.33,\n",
        "                                                    random_state=42)\n",
        "# Define a Sequential model\n",
        "model = Sequential()\n",
        "# Add layers to the model with L1 regularization\n",
        "model.add(Dense(500, input_dim=2, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train,validation_data=(X_test, y_test),\n",
        "                    epochs=1000, verbose=0)\n",
        "# Plot loss history\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.title('Loss History')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rtBacRVyBD4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_l1_model = Sequential()\n",
        "# Add layers to the model with L1 regularization\n",
        "reg_l1_model.add(Dense(500, input_dim=2, activation='relu',\n",
        "                       kernel_regularizer=tf.keras.regularizers.l1(0.01)))\n",
        "reg_l1_model.add(Dense(1, activation='sigmoid',\n",
        "                       kernel_regularizer=tf.keras.regularizers.l1(0.01)))\n",
        "# Compile the model\n",
        "reg_l1_model.compile(loss='binary_crossentropy',optimizer='adam',\n",
        "                     metrics=['accuracy'])\n",
        "# Train the model\n",
        "history = reg_l1_model.fit(X_train, y_train,validation_data=(X_test, y_test),\n",
        "                           epochs=1000, verbose=0)\n",
        "# Plot loss history\n",
        "plt.plot(history.history['loss'], label='train')\n",
        "plt.plot(history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.title('Loss History with L1 Regularizer')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_dfDURWwBFly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg_l2_model = Sequential()\n",
        "reg_l2_model.add(Dense(500, input_dim=2, activation='relu',\n",
        "                       kernel_regularizer='l2'))\n",
        "reg_l2_model.add(Dense(1, activation='sigmoid', kernel_regularizer='l2'))\n",
        "reg_l2_model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "reg_history = reg_l2_model.fit(X_train, y_train,\n",
        "                            validation_data=(X_test, y_test),\n",
        "                            epochs=1000, verbose=0)\n",
        "\n",
        "plt.plot(reg_history.history['loss'], label='train')\n",
        "plt.plot(reg_history.history['val_loss'], label='test')\n",
        "plt.legend()\n",
        "plt.title('Loss History with L2 regularizer')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dRo9RrceBHRY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kLnNMkh-BJlj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}